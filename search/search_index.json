{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to GRFlood A Python package for flood forecasting GitHub repo: https://github.com/callback21/GRFlood PyPI: https://pypi.org/project/GRFlood Conda-forge: https://anaconda.org/conda-forge/GRFlood Free software: MIT license Introduction GRFlood is a Python package for flood forecasting by Training several popular statistical models to predict regional flooding,and compare the performance of each model.We will use the Root Mean Square Error(RMSE) metric to evaluate each model\u2019s performance, and then normalize each of these statistics by dividing each of them by the difference of the max and min training values in order to make performance comparisons across models.","title":"Home"},{"location":"#welcome-to-grflood","text":"A Python package for flood forecasting GitHub repo: https://github.com/callback21/GRFlood PyPI: https://pypi.org/project/GRFlood Conda-forge: https://anaconda.org/conda-forge/GRFlood Free software: MIT license","title":"Welcome to GRFlood"},{"location":"#introduction","text":"GRFlood is a Python package for flood forecasting by Training several popular statistical models to predict regional flooding,and compare the performance of each model.We will use the Root Mean Square Error(RMSE) metric to evaluate each model\u2019s performance, and then normalize each of these statistics by dividing each of them by the difference of the max and min training values in order to make performance comparisons across models.","title":"Introduction"},{"location":"Get_Started/","text":"This Get Started guide is intended as a quick example to start programming with GRFlood . \u25ba Let's install our package. In : pip install GRFlood \u25ba Upload our class Flood . In : from GRFlood import Flood \u25ba Creates an instance of the class Flood . In : model = Flood('Example_Water_Volume.csv') Out : Example_Water_Volume.csv(application/vnd.ms-excel) - 99369 bytes, last modified: 23/02/2021 - 100% done Saving Example_Water_Volume.csv to Example_Water_Volume.csv new Q (l/s) Date 1999-01-01 910 1999-01-02 900 1999-01-03 900 1999-01-04 890 1999-01-05 890 ... ... 2016-12-27 290 2016-12-28 290 2016-12-29 290 2016-12-30 290 2016-12-31 290 [6575 rows x 1 columns] \u25ba To view our data you can print. In : model.data Out : new Q (l/s) Date 1999-01-01 910 1999-01-02 900 1999-01-03 900 1999-01-04 890 1999-01-05 890 ... ... 2016-12-27 290 2016-12-28 290 2016-12-29 290 2016-12-30 290 2016-12-31 290 6575 rows \u00d7 1 columns \u25ba Normalized our data. In : model.normalized_features(model.data) Out: [[0.0155052 ] [0.01533481] [0.01533481] ... [0.00494122] [0.00494122] [0.00494122]] \u25ba To view our normalized data you can print. In : model.dataset Out : array([[0.0155052 ], [0.01533481], [0.01533481], ..., [0.00494122], [0.00494122], [0.00494122]]) \u25ba Split our data. In : model.split(model.dataset, ratio = 75) Out : 6575 train size: 4931 and test size : 1644 \u25ba To view more details about split. In : print(\"train data :{} \\n test data : {} \\n train size : {} \\n test size : {} \".format(model.train,model.test,model.train_size,model.test_size)) Out : train data :[[0.0155052 ] [0.01533481] [0.01533481] ... [0.00460044] [0.00460044] [0.00443006]] test data : [[0.00425967] [0.00425967] [0.00408928] ... [0.00494122] [0.00494122] [0.00494122]] train size : 4931 test size : 1644 \u25ba Checking stationarity, we\u2019ll be using the rolling statistics plots along with Dickey-Fuller test results. For Dicky Fuller Test : Null hypothesis in ADF test is that Data is not stationary. It\u2019s better to have the p-value to be smaller than 0.05 inorder to reject the null hypothesis and consider data as stationary. If Test Statistic < Critical Values => Rejects the null hypothesis. If Test Statistic >Critical Values => failed to reject the null hypothesis In : model.test_stationarity(model.data['new Q (l/s)']) \u25ba In our example we can understand that my test statistics value = -8.097405e+00 is smaller than critical value(5%) = -2.861982e+00, Thus the data is stationary. If the data is not stationary we have to tranform it to make the data more stationary, using differencing technique for example. Out : Results of Dickey-Fuller Test: Test Statistic -8.097405e+00 p-value 1.327622e-12 #Lags Used 3.400000e+01 Number of Observations Used 6.540000e+03 Critical Value (1%) -3.431350e+00 Critical Value (5%) -2.861982e+00 Critical Value (10%) -2.567005e+00 dtype: float64 \u25ba We now experiment with the following three models: 1. Artificial Neural Network 2. Recurrent Neural Network 3. Long Short-Term Memory (a RNN with a LSTM layer) \u25ba Plot of the predictions made by the ANN . In : model.ANN_model(train = model.train, test = model.test, train_size = model.train_size, data = model.data, look_back = 20) Out : Test Score: 1858.73 RMSE Normalized RMSE: 0.03167030826699024 \u25ba Plot of the predictions made by the LSTM . In : model.LSTM_model(train = model.train, test = model.test, train_size = model.train_size, data = model.data, look_back = 20) Out : Test Score: 1828.80 RMSE Normalized RMSE: 0.031160290158361494 \u25ba Plot of the predictions made by the RNN . In : model.RNN(train = model.train, test = model.test, train_size = model.train_size, data = model.data, look_back = 20) Out : Test Score: 1946.10 RMSE Normalized RMSE: 0.033158903327623425","title":"Get Started"},{"location":"Installation/","text":"Installation Install from PyPI GRFlood is available on PyPI. To install GRFlood , run this command in your terminal: pip install GRFlood Install from conda-forge GRFlood is also available on conda-forge. If you have Anaconda or Miniconda installed on your computer, you can create a conda Python environment to install GRFlood : conda install -c defaults -c conda-forge GRFlood Install from GitHub To install the development version from GitHub using Git, run the following command in your terminal: pip install git+https://github.com/callback21/GRFlood Colaboratory Colaboratory lets you connect to a local runtime using Jupyter. This allows you to execute code on your local hardware and have access to your local file system. Step 1: Install Jupyter Install Jupyter on your local machine. Step 2: Install and enable the jupyter_http_over_ws jupyter extension (one-off) The jupyter_http_over_ws extension is authored by the Colaboratory team and available on GitHub . pip install jupyter_http_over_ws jupyter serverextension enable --py jupyter_http_over_ws Step 3: Start server and authenticate New notebook servers are started normally, though you will need to set a flag to explicitly trust WebSocket connections from the Colaboratory frontend. Once the server has started, it will print a message with the initial backend URL used for authentication. Make a copy of this URL as you'll need to provide this in the next step. jupyter notebook \\ --NotebookApp.allow_origin='https://colab.research.google.com' \\ --port=8888 \\ --NotebookApp.port_retries=0 Step 4: Connect to the local runtime In Colaboratory, click the 'Connect' button and select 'Connect to local runtime\u2026'. Enter the URL from the previous step in the dialogue that appears and click the 'Connect' button. After this, you should now be connected to your local runtime. Upgrade GRFlood If you ha ve installed GRFlood before and want to upgrade to the latest version, you can run the following command in your terminal: pip install -U GRFlood If you use conda, you can update GRFlood to the latest version by running the following command in your terminal: conda update GRFlood","title":"Installation"},{"location":"Installation/#installation","text":"","title":"Installation"},{"location":"Installation/#install-from-pypi","text":"GRFlood is available on PyPI. To install GRFlood , run this command in your terminal: pip install GRFlood","title":"Install from PyPI"},{"location":"Installation/#install-from-conda-forge","text":"GRFlood is also available on conda-forge. If you have Anaconda or Miniconda installed on your computer, you can create a conda Python environment to install GRFlood : conda install -c defaults -c conda-forge GRFlood","title":"Install from conda-forge"},{"location":"Installation/#install-from-github","text":"To install the development version from GitHub using Git, run the following command in your terminal: pip install git+https://github.com/callback21/GRFlood","title":"Install from GitHub"},{"location":"Installation/#colaboratory","text":"Colaboratory lets you connect to a local runtime using Jupyter. This allows you to execute code on your local hardware and have access to your local file system. Step 1: Install Jupyter Install Jupyter on your local machine. Step 2: Install and enable the jupyter_http_over_ws jupyter extension (one-off) The jupyter_http_over_ws extension is authored by the Colaboratory team and available on GitHub . pip install jupyter_http_over_ws jupyter serverextension enable --py jupyter_http_over_ws Step 3: Start server and authenticate New notebook servers are started normally, though you will need to set a flag to explicitly trust WebSocket connections from the Colaboratory frontend. Once the server has started, it will print a message with the initial backend URL used for authentication. Make a copy of this URL as you'll need to provide this in the next step. jupyter notebook \\ --NotebookApp.allow_origin='https://colab.research.google.com' \\ --port=8888 \\ --NotebookApp.port_retries=0 Step 4: Connect to the local runtime In Colaboratory, click the 'Connect' button and select 'Connect to local runtime\u2026'. Enter the URL from the previous step in the dialogue that appears and click the 'Connect' button. After this, you should now be connected to your local runtime.","title":"Colaboratory"},{"location":"Installation/#upgrade-grflood","text":"If you ha ve installed GRFlood before and want to upgrade to the latest version, you can run the following command in your terminal: pip install -U GRFlood If you use conda, you can update GRFlood to the latest version by running the following command in your terminal: conda update GRFlood","title":"Upgrade GRFlood"},{"location":"Usage/","text":"Below is a list of some commonly used functions,and class available in the GRFlood Python package. Flood(file_name) Class to defined your project instance and initialize your data to train several popular statistical models to predict regional flooding. Parametres : Name Type Description Default file_name path object or file-like object Any valid string path is acceptable. The string could be a URL. Valid URL schemes include http, ftp, s3, gs, and file. For file URLs, a host is expected. A local file could be: file://localhost/path/to/table.csv.If you want to pass in a path object, pandas accepts any os.PathLike.By file-like object, we refer to objects with a read() method, such as a file handle (e.g. via builtin open function) or StringIO. required instance.data(file_name) Method to upload your data and visualize them. Parametres : Name Type Description Default file_name path object or file-like object Any valid string path is acceptable. The string could be a URL.A local file could be: file://localhost/path/to/table.csv.If you want to pass in a path object,we refer to objects with a read() method, or StringIO. required instance.normalized_features(data) Refers to rescaling real-valued numeric attributes into a 0 to 1 range. Data normalization is used to make model training less sensitive to the scale of features. This allows our model to converge to better weights and, in turn, leads to a more accurate model. * Parametres : Name Type Description Default data ndarray, DataFrame can contain Series, arrays get from instande.data(file_name), constants, dataclass or list-like objects. required instance.split(dataset, ratio) Split your data into train data and test data. Parametres : Name Type Description Default dataset ndarray, DataFrame can contain Series, arrays get from instande.data(file_name), constants, dataclass or list-like objects. required ratio float the ratio of your train data to train your model 75 instance.test_stationarity(timeseries) Checking stationarity, we\u2019ll be using the rolling statistics plots along with Dickey-Fuller test results. Parametres : Name Type Description Default timeseries array_like, 1d Any scalar or sequence that can be interpreted as an ndarray to test stationarity. required instance.ANN_model(train, test, train_size, data ,look_back = 1 ) Artificial Neural Network model. Parametres : Name Type Description Default train array_like contain ndarray of your train data (it can be extract from instance.train derived from split method). required test array_like contain ndarray of your test data (it can be extracted from instance.train derived from split method). required train_size int size of train data required data ndarray, DataFrame can contain Series, arrays get from instande.data(file_name), constants, dataclass or list-like objects. required look_back float window size 1 instance.LSTM_model(train, test, train_size, data ,look_back = 1 ) Long Short-Term Memory model. Parametres : Name Type Description Default train array_like contain ndarray of your train data (it can be extract from instance.train derived from split method). required test array_like contain ndarray of your test data (it can be extracted from instance.train derived from split method). required train_size int size of train data required data ndarray, DataFrame can contain Series, arrays get from instande.data(file_name), constants, dataclass or list-like objects. required look_back float window size 1 instance.RNN_model(train, test, train_size, data ,look_back = 1 ) Recurrent Neural Network model. Parametres : Name Type Description Default train array_like contain ndarray of your train data (it can be extract from instance.train derived from split method). required test array_like contain ndarray of your test data (it can be extracted from instance.train derived from split method). required train_size int size of train data required data ndarray, DataFrame can contain Series, arrays get from instande.data(file_name), constants, dataclass or list-like objects. required look_back float window size 1 differencing(data, periods = 1 ) This mostly works well in improving stationarity.One of the most common methods of dealing with both trend(variation in the mean over time) and seasonality is differencing. In this technique, we take the difference of the observation at a particular instant with that at the previous instant. Parametres : Name Type Description Default data ndarray, DataFrame can contain Series, arrays get from instande.data(file_name), constants, dataclass or list-like objects. required periods int Number of periods to shift. Can be positive or negative. 1 moving_average(timeseries, window) In this approach, we take average of \u2018k\u2019 consecutive values depending on the frequency of time series,to deal with trend(variation in the mean over time) Parametres : Name Type Description Default timeseries array_like, 1d Any scalar or sequence that can be interpreted as an ndarray to test stationarity. required window int Size of the moving window. This is the number of observations used for calculating the statistic. Each window will be a fixed size. required","title":"Usage"},{"location":"about/","text":"Package Name GRFlood Version VERSION : 1.0.0 Authors AMIRA AYOUB Futur rural engineering and python developer. MOHAMED RAZZOUGUI Futur rural engineering and python developer. MISSER ABDELAALI Futur rural engineering and python developer. SOUASSI ISSAM Futur rural engineering and python developer.","title":"About"},{"location":"about/#package-name","text":"GRFlood","title":"Package Name"},{"location":"about/#version","text":"VERSION : 1.0.0","title":"Version"},{"location":"about/#authors","text":"AMIRA AYOUB Futur rural engineering and python developer. MOHAMED RAZZOUGUI Futur rural engineering and python developer. MISSER ABDELAALI Futur rural engineering and python developer. SOUASSI ISSAM Futur rural engineering and python developer.","title":"Authors"}]}